{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayesClassifier:\n",
    "    def __init__(self, trainingFile, testingFile, threshold=5):\n",
    "        self.Xtrain = numpy.loadtxt(trainingFile)\n",
    "        self.n = self.Xtrain.shape[0] # number of training examples\n",
    "        self.d = self.Xtrain.shape[1]-1 # number of features in each example\n",
    "    \n",
    "        \"\"\"\n",
    "        - Threshold for separating categorical and continuous features\n",
    "        - Represents number of distinct values in a column\n",
    "        \"\"\"\n",
    "        self.threshold = threshold \n",
    "\n",
    "\n",
    "        self.Xtest = numpy.loadtxt(testingFile)\n",
    "        self.nn = self.Xtest.shape[0] # Number of points in the testing data.\n",
    "\n",
    "        self.pos_idx = set() # map of positive example indices\n",
    "        self.neg_idx = set() # map of negative example indices\n",
    "\n",
    "        self.tp = 0 #True Positive\n",
    "        self.fp = 0 #False Positive\n",
    "        self.tn = 0 #True Negative\n",
    "        self.fn = 0 #False Negative\n",
    "\n",
    "        # we need to call the functions below to initialize the model\n",
    "        self.find_idx_sets()\n",
    "        self.p_positive, self.p_negative = self.main_class_probability()\n",
    "    \n",
    "\n",
    "    def col_type(self, column):\n",
    "        \"\"\"\n",
    "        column: the column index to determine the type of\n",
    "        Determine if the column is categorical or continuous.\n",
    "\n",
    "        - Categorical if the number of distinct values is less than the threshold\n",
    "        - Continuous if the number of distinct values is greater than the threshold\n",
    "        \"\"\"\n",
    "        distinct_values = set()\n",
    "        for i in range(self.n):\n",
    "            distinct_values.add(self.Xtrain[i][column])\n",
    "    \n",
    "        if len(distinct_values) < self.threshold:\n",
    "            # Categorical\n",
    "            return 0\n",
    "        else:\n",
    "            # Continuous\n",
    "            return 1\n",
    "    \n",
    "\n",
    "    def calc_col_mean(self, indexes, column):\n",
    "        \"\"\"\n",
    "        indexes: can be pos_idx or neg_idx \n",
    "        column: the column index to calculate mean for\n",
    "        Calculate mean of a column in the training data for the given indexes.\n",
    "        \"\"\"\n",
    "\n",
    "        total = 0\n",
    "        for i in indexes:\n",
    "            total += self.Xtrain[i][column]\n",
    "        mean = total / len(indexes)\n",
    "                \n",
    "        return mean\n",
    "    \n",
    "    \n",
    "    def calc_col_std(self, indexes, column):\n",
    "        \"\"\"\n",
    "        indexes: can be pos_idx or neg_idx \n",
    "        column: the column index to calculate std for\n",
    "        Calculate std of a column in the training data for the given indexes.\n",
    "        \"\"\"\n",
    "        total = 0\n",
    "        for i in indexes:\n",
    "            total += (self.Xtrain[i][column] - self.calc_col_mean(indexes, column))**2\n",
    "        std = (total / len(indexes))**0.5\n",
    "                \n",
    "        return std\n",
    "    \n",
    "\n",
    "    def find_idx_sets(self):\n",
    "        \"\"\"\n",
    "        Find the positive and negative example indices in the training data.\n",
    "        \"\"\"\n",
    "        for element in range(0, self.n):\n",
    "            if self.Xtrain[element][4] == 1.0:\n",
    "                self.pos_idx.add(element)\n",
    "            else:\n",
    "                self.neg_idx.add(element)\n",
    "        return len(self.pos_idx), len(self.neg_idx)\n",
    "\n",
    "\n",
    "    def main_class_probability(self):\n",
    "        \"\"\"\n",
    "        Calculate the prior probabilities of positive and negative classes.\n",
    "        p_positive: probability of positive class\n",
    "        p_negative: probability of negative class\n",
    "        \"\"\"\n",
    "        p_positive = len(self.pos_idx) / self.n\n",
    "        p_negative = len(self.neg_idx) / self.n\n",
    "        return p_positive, p_negative\n",
    "    \n",
    "\n",
    "    def print_stats(self):\n",
    "        \"\"\"\n",
    "        Print the statistics of the classifier.\n",
    "        \"\"\"\n",
    "        print(f\"True Positives: {self.tp}\")\n",
    "        print(f\"False Positives: {self.fp}\")\n",
    "        print(f\"True Negatives: {self.tn}\")\n",
    "        print(f\"False Negatives: {self.fn}\")\n",
    "        \n",
    "        accuracy = (self.tp + self.tn) / (self.tp + self.tn + self.fp + self.fn)\n",
    "        print(f\"Accuracy: {accuracy:.2f}\")\n",
    "        \n",
    "        precision = self.tp / (self.tp + self.fp)\n",
    "        print(f\"Precision: {precision:.2f}\")\n",
    "        \n",
    "        recall = self.tp / (self.tp + self.fn)\n",
    "        print(f\"Recall: {recall:.2f}\")\n",
    "\n",
    "    \n",
    "    def classify(self):\n",
    "        for row in range(self.nn):\n",
    "            curr_prob_pos = 1.0\n",
    "            curr_prob_neg = 1.0\n",
    "\n",
    "            for col in range(self.d):\n",
    "                if self.col_type(col) == 0:\n",
    "                    # if categorical, find the probability of that feature given the class\n",
    "                    # use the count of the feature in the training data to calculate the probability of that feature given the class\n",
    "\n",
    "                    count_pos = 0\n",
    "                    count_neg = 0\n",
    "                    for i in self.pos_idx:\n",
    "                        if self.Xtrain[i][col] == self.Xtest[row][col]:\n",
    "                            count_pos += 1\n",
    "                    for i in self.neg_idx:\n",
    "                        if self.Xtrain[i][col] == self.Xtest[row][col]:\n",
    "                            count_neg += 1\n",
    "                    # calculate the probability of that feature given the class\n",
    "                    prob_pos = count_pos / len(self.pos_idx)\n",
    "                    prob_neg = count_neg / len(self.neg_idx)\n",
    "                    # multiply the probability of that feature given the class with the current probability\n",
    "                    curr_prob_pos *= prob_pos\n",
    "                    curr_prob_neg *= prob_neg\n",
    "\n",
    "                elif self.col_type(col) == 1:\n",
    "                    # if continuous, find the mean and std of that feature given the class  \n",
    "                    col_pos_mean = self.calc_col_mean(self.pos_idx, col)\n",
    "                    col_pos_std = self.calc_col_std(self.pos_idx, col)\n",
    "                    col_neg_mean = self.calc_col_mean(self.neg_idx, col)\n",
    "                    col_neg_std = self.calc_col_std(self.neg_idx, col)\n",
    "\n",
    "                    # calculate the probability of that feature given the class\n",
    "                    curr_prob_pos *= norm.pdf(self.Xtest[row][col], col_pos_mean, col_pos_std)\n",
    "                    curr_prob_neg *= norm.pdf(self.Xtest[row][col], col_neg_mean, col_neg_std)\n",
    "                    \n",
    "            # calculate the posterior probabilities\n",
    "            curr_prob_pos *= self.p_positive\n",
    "            curr_prob_neg *= self.p_negative\n",
    "\n",
    "            # print(f\"{curr_prob_pos=}, {curr_prob_neg=} \")\n",
    "            \n",
    "            # classify the row example\n",
    "            if curr_prob_pos > curr_prob_neg:\n",
    "                if self.Xtest[row][4] == 1.0:\n",
    "                    self.tp += 1\n",
    "                else:\n",
    "                    print(f\"False Positive at {row=}: \")\n",
    "                    print(f\"Predicted Class: \", 1.0)\n",
    "                    print(f\"Actual Class: {self.Xtest[row][4]}\\n\")\n",
    "                    self.fp += 1\n",
    "            else:\n",
    "                if self.Xtest[row][4] == -1.0:\n",
    "                    self.tn += 1\n",
    "                else:\n",
    "                    print(f\"False Positive at {row=}: \")\n",
    "                    print(f\"Predicted Class: \", -1.0)\n",
    "                    print(f\"Actual Class: {self.Xtest[row][4]}\\n\")\n",
    "                    self.fn += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing and Classifying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "irisTrainingFile = \"./misc/irisTraining.txt\"\n",
    "irisTestingFile = \"./misc/irisTesting.txt\"\n",
    "\n",
    "buyTrainingFile = \"./misc/buyTraining.txt\"\n",
    "buyTestingFile = \"./misc/buyTesting.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False Positive at row=17: \n",
      "Predicted Class:  1.0\n",
      "Actual Class: -1.0\n",
      "\n",
      "True Positives: 16\n",
      "False Positives: 1\n",
      "True Negatives: 33\n",
      "False Negatives: 0\n",
      "Accuracy: 0.98\n",
      "Precision: 0.94\n",
      "Recall: 1.00\n"
     ]
    }
   ],
   "source": [
    "iris_classifier = NaiveBayesClassifier(irisTrainingFile, irisTestingFile)\n",
    "iris_classifier.classify()\n",
    "iris_classifier.print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False Positive at row=0: \n",
      "Predicted Class:  1.0\n",
      "Actual Class: -1.0\n",
      "\n",
      "True Positives: 2\n",
      "False Positives: 1\n",
      "True Negatives: 1\n",
      "False Negatives: 0\n",
      "Accuracy: 0.75\n",
      "Precision: 0.67\n",
      "Recall: 1.00\n"
     ]
    }
   ],
   "source": [
    "buy_classifier = NaiveBayesClassifier(buyTrainingFile, buyTestingFile)\n",
    "buy_classifier.classify()\n",
    "buy_classifier.print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
